## Natural Language Processing

- Machine learning
  - Supervised
    - Classification
      - datasets are inputed
      - a model is created a trained with the dataset to make predictions.
      - most of the datasets are made up of texts.
      - e.g. spam classification.
    - Rgression
  - Unsupervised

## Roadmap

- Text Pre-processing(Cleaning the text)

  - Tokenization : convert paragraphs into sentences, sentences into words
  - Lemmetization
  - Stemming
  - Stop words

- Text Pre-processing(Converting input text to vectors)

  - Bag of Words
  - TFIDF
  - Unigram
  - Bigrams
  - Word Embedding

- Neural Networks (Deep learning technique)

  - word2Vec
  - avgWord2Vec
  - RNN
  - LTSM RNN
  - GRU RNN

- Transformer
- BERT

# Toenization

converting text contents into tokens.

- Corpus : Paragraphs
- Documents : Sentences
- Vocabulary : Unique Words
- Words

Paragraphs => Sentences => Unique Words (Vocabulary)
